# -*- coding: utf-8 -*-
"""Cross_validation_parameter_tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17NDFarqcOZQubbwLgnT0SO6Wua_rJqA6
"""

'''To implement K-fold cross-validation, we use a scikit_learn wrapper in Keras: KerasClassifier. 
In other words, we use Keras to build the model and use scikit_learn for cross-validation. '''

import tensorflow as tf
from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score

def build_classifier(optimizer):
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))
  model.add(tf.keras.layers.Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))
  model.add(tf.keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
  model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])
  return model

my_model = KerasClassifier(build_fn = build_classifier)

# create dataset
import pandas as pd
dataset = pd.read_csv('Churn_Modelling.csv')  
X = dataset.iloc[:, 3: 13].values
y = dataset.iloc[:, 13].values

from sklearn.preprocessing import LabelEncoder
labelencoder_X_1 = LabelEncoder() #instantiate an object of the class LabelEncoder
X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1]) #ordinal encoding for column 1

labelencoder_X_2 = LabelEncoder()
X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2]) #ordinal encoding for column 2

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
import numpy as np
ct = ColumnTransformer( #'encoder' is the name of the column transformer
    [('encoder', OneHotEncoder(), [1])],    # The column numbers to be transformed (here is [1] but can be [0, 1, 3])
    remainder='passthrough'                         # Leave the rest of the columns untouched
)
X = np.array(ct.fit_transform(X), dtype=np.float)

X = X[:, 1:]

#Standardise the data (x_standardised = (x - x_mean)/std_dev)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
'''X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test) #note that we use the scale set from the training set to transform the test set'''
X = sc.fit_transform(X)

parameters = {'batch_size': [20, 30], 'nb_epoch': [50, 100], 'optimizer': ['adam', 'sgd']}

grid_search = GridSearchCV(estimator=my_model, param_grid=parameters, scoring = 'accuracy', cv = 10)

grid_search = grid_search.fit(X, y)

best_parameters = grid_search.best_params_
best_accuracy = grid_search.best_score_

print(best_parameters)
print(best_accuracy)

